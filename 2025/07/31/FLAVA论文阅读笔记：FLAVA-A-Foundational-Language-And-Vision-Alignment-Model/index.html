<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="论文标题： FLAVA: A Foundational Language And Vision Alignment Model作者： Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, et al.论文链接： arXiv:2112.04482">
<meta property="og:type" content="article">
<meta property="og:title" content="FLAVA论文阅读笔记：FLAVA: A Foundational Language And Vision Alignment Model">
<meta property="og:url" content="http://example.com/2025/07/31/FLAVA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AFLAVA-A-Foundational-Language-And-Vision-Alignment-Model/index.html">
<meta property="og:site_name" content="QianQing&#39;s Blog">
<meta property="og:description" content="论文标题： FLAVA: A Foundational Language And Vision Alignment Model作者： Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, et al.论文链接： arXiv:2112.04482">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://picx.zhimg.com/70/v2-e1d5a4f63031d86fae317b98bab74263_1440w.avis?source=172ae18b&amp;biz_tag=Post">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/3cb63ff434bb351db94afbef3257c78f.png">
<meta property="og:image" content="https://picx.zhimg.com/70/v2-e1d5a4f63031d86fae317b98bab74263_1440w.avis?source=172ae18b&amp;biz_tag=Post">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/b8bdf6141c6c47e0f947de17bf1d8478.png">
<meta property="article:published_time" content="2025-07-30T16:19:31.000Z">
<meta property="article:modified_time" content="2025-07-30T17:02:10.985Z">
<meta property="article:author" content="千顷QianQing">
<meta property="article:tag" content="FLAVA">
<meta property="article:tag" content="多模态">
<meta property="article:tag" content="ViT">
<meta property="article:tag" content="VLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picx.zhimg.com/70/v2-e1d5a4f63031d86fae317b98bab74263_1440w.avis?source=172ae18b&amp;biz_tag=Post">


<link rel="canonical" href="http://example.com/2025/07/31/FLAVA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AFLAVA-A-Foundational-Language-And-Vision-Alignment-Model/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2025/07/31/FLAVA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AFLAVA-A-Foundational-Language-And-Vision-Alignment-Model/","path":"2025/07/31/FLAVA论文阅读笔记：FLAVA-A-Foundational-Language-And-Vision-Alignment-Model/","title":"FLAVA论文阅读笔记：FLAVA: A Foundational Language And Vision Alignment Model"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>FLAVA论文阅读笔记：FLAVA: A Foundational Language And Vision Alignment Model | QianQing's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">QianQing's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%8F%90%E5%87%BAFLAVA%EF%BC%9F"><span class="nav-number">1.</span> <span class="nav-text">1. 为什么提出FLAVA？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E6%80%BB%E8%A7%88"><span class="nav-number">2.</span> <span class="nav-text">2. 模型结构总览</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9B%AE%E6%A0%87%E4%B8%8E%E7%AD%96%E7%95%A5"><span class="nav-number">3.</span> <span class="nav-text">3. 预训练目标与策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-%E5%8D%95%E6%A8%A1%E6%80%81%E7%9B%AE%E6%A0%87"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 单模态目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%AE%E6%A0%87"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 多模态目标</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E5%9B%BE%E6%96%87%E5%AF%B9%E6%AF%94%E6%8D%9F%E5%A4%B1%EF%BC%9AGlobal-Contrastive-Loss"><span class="nav-number">3.2.1.</span> <span class="nav-text">（1）图文对比损失：Global Contrastive Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%9B%BE%E6%96%87%E5%8C%B9%E9%85%8D%E4%BB%BB%E5%8A%A1%EF%BC%9AImage-Text-Matching-ITM"><span class="nav-number">3.2.2.</span> <span class="nav-text">（2）图文匹配任务：Image-Text Matching (ITM)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E6%8E%A9%E7%A0%81%E5%A4%9A%E6%A8%A1%E6%80%81%E5%BB%BA%E6%A8%A1%EF%BC%9AMasked-Multimodal-Modeling-MMM"><span class="nav-number">3.2.3.</span> <span class="nav-text">（3）掩码多模态建模：Masked Multimodal Modeling (MMM)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E6%A8%A1%E5%9D%97%E6%BF%80%E6%B4%BB%E7%AD%96%E7%95%A5%EF%BC%9ARound-Robin"><span class="nav-number">4.</span> <span class="nav-text">4. 模块激活策略：Round-Robin</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E9%80%82%E9%85%8D%E6%96%B9%E5%BC%8F"><span class="nav-number">5.</span> <span class="nav-text">5. 下游任务适配方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E4%BA%AE%E7%82%B9"><span class="nav-number">6.</span> <span class="nav-text">6. 实验结果亮点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-%E6%88%91%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E6%80%BB%E7%BB%93"><span class="nav-number">7.</span> <span class="nav-text">7. 我的理解与总结</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="千顷QianQing"
      src="/images/touxiang.jpg">
  <p class="site-author-name" itemprop="name">千顷QianQing</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">102</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/qianqing26" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qianqing26" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:eevee_hbc@outlook.com" title="E-Mail → mailto:eevee_hbc@outlook.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/31/FLAVA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AFLAVA-A-Foundational-Language-And-Vision-Alignment-Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpg">
      <meta itemprop="name" content="千顷QianQing">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="QianQing's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="FLAVA论文阅读笔记：FLAVA: A Foundational Language And Vision Alignment Model | QianQing's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          FLAVA论文阅读笔记：FLAVA: A Foundational Language And Vision Alignment Model
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-07-31 00:19:31 / Modified: 01:02:10" itemprop="dateCreated datePublished" datetime="2025-07-31T00:19:31+08:00">2025-07-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A0%94%E9%9B%B6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">研零学习记录</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><strong>论文标题：</strong> <em>FLAVA: A Foundational Language And Vision Alignment Model</em><br><strong>作者：</strong> Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, et al.<br><strong>论文链接：</strong> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.04482">arXiv:2112.04482</a></p>
<p><img src="https://picx.zhimg.com/70/v2-e1d5a4f63031d86fae317b98bab74263_1440w.avis?source=172ae18b&amp;biz_tag=Post" alt=""></p>
<span id="more"></span>
<h2 id="1-为什么提出FLAVA？"><a href="#1-为什么提出FLAVA？" class="headerlink" title="1. 为什么提出FLAVA？"></a>1. 为什么提出FLAVA？</h2><p>当前多模态预训练模型存在两种主流：</p>
<ol>
<li><p><strong>对比式双编码器（CLIP/ALIGN）</strong>  </p>
<ul>
<li>模态分开训练 → 适合检索（图文对齐）  </li>
<li>缺点：无法处理复杂融合任务（如VQA）</li>
</ul>
</li>
<li><p><strong>融合式单编码器（UNITER/ViLT）</strong>  </p>
<ul>
<li>模态融合 → 擅长推理  </li>
<li>缺点：难以泛化到单模态任务</li>
</ul>
<p><strong>FLAVA 的目标</strong>是构建一个真正意义上的“<strong>通用基础多模态模型</strong>”，能够同时支持：</p>
</li>
</ol>
<ul>
<li>单模态视觉任务（如图像分类）</li>
<li>单模态语言任务（如情感分类）</li>
<li>跨模态任务（如VQA、图文检索）</li>
</ul>
<p>它使用统一的 Transformer 结构训练三个子编码器，使模型既能解耦又能融合，成为“语言-视觉齐头并进”的基础模型。</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/3cb63ff434bb351db94afbef3257c78f.png" alt=""></p>
<hr>
<h2 id="2-模型结构总览"><a href="#2-模型结构总览" class="headerlink" title="2. 模型结构总览"></a>2. 模型结构总览</h2><p>FLAVA 架构包含三大模块，均基于 ViT 构建：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>编码器模块</th>
<th>输入内容</th>
<th>输出 [CLS] Token</th>
<th>用于任务</th>
</tr>
</thead>
<tbody>
<tr>
<td>Image Encoder</td>
<td>图像 patch</td>
<td><code>[CLS_I]</code></td>
<td>图像分类、对比学习</td>
</tr>
<tr>
<td>Text Encoder</td>
<td>文本 tokens</td>
<td><code>[CLS_T]</code></td>
<td>文本分类、对比学习</td>
</tr>
<tr>
<td>Multimodal Encoder</td>
<td><code>[hI] + [hT]</code></td>
<td><code>[CLS_M]</code></td>
<td>多模态推理类任务</td>
</tr>
</tbody>
</table>
</div>
<p>各模块使用标准 Transformer（MHA + FFN + 残差 + LN），仅嵌入方式不同。</p>
<p><img src="https://picx.zhimg.com/70/v2-e1d5a4f63031d86fae317b98bab74263_1440w.avis?source=172ae18b&amp;biz_tag=Post" alt=""></p>
<hr>
<h2 id="3-预训练目标与策略"><a href="#3-预训练目标与策略" class="headerlink" title="3. 预训练目标与策略"></a>3. 预训练目标与策略</h2><h3 id="3-1-单模态目标"><a href="#3-1-单模态目标" class="headerlink" title="3.1 单模态目标"></a>3.1 单模态目标</h3><p>用于提升图像/文本各自的表示学习能力：</p>
<ul>
<li><p><strong>Masked Image Modeling (MIM)</strong>：图像版的BERT  </p>
<ul>
<li>输入：mask部分patch  </li>
<li>输出：预测dVAE token（类似BEiT）  </li>
<li>损失函数：交叉熵</li>
</ul>
</li>
<li><p><strong>Masked Language Modeling (MLM)</strong>：文本mask预测  </p>
<ul>
<li>15% BERT-style masking  </li>
<li>输出：预测token ID  </li>
<li>损失函数：交叉熵</li>
</ul>
</li>
</ul>
<h3 id="3-2-多模态目标"><a href="#3-2-多模态目标" class="headerlink" title="3.2 多模态目标"></a>3.2 多模态目标</h3><p>用于学习图文间的对齐、融合与生成：</p>
<h4 id="（1）图文对比损失：Global-Contrastive-Loss"><a href="#（1）图文对比损失：Global-Contrastive-Loss" class="headerlink" title="（1）图文对比损失：Global Contrastive Loss"></a>（1）图文对比损失：<strong>Global Contrastive Loss</strong></h4><ul>
<li>输入：图像+文本对</li>
<li>输出：两个 [CLS] 向量</li>
<li>损失函数：</li>
</ul>
<script type="math/tex; mode=display">
\mathcal{L}_{GC} = -\frac{1}{N}\sum_{i=1}^N \log \frac{\exp(\text{sim}(v_i, t_i)/\tau)}{\sum_{j=1}^N \exp(\text{sim}(v_i, t_j)/\tau)}</script><p>与 CLIP 相同，鼓励图文对应对齐。</p>
<h4 id="（2）图文匹配任务：Image-Text-Matching-ITM"><a href="#（2）图文匹配任务：Image-Text-Matching-ITM" class="headerlink" title="（2）图文匹配任务：Image-Text Matching (ITM)"></a>（2）图文匹配任务：<strong>Image-Text Matching (ITM)</strong></h4><ul>
<li>使用 Multimodal Encoder 的 <code>[CLS_M]</code> → 过MLP → 输出是否配对</li>
</ul>
<script type="math/tex; mode=display">
\mathcal{L}_{ITM} = - y \log p + (1 - y) \log (1 - p)</script><h4 id="（3）掩码多模态建模：Masked-Multimodal-Modeling-MMM"><a href="#（3）掩码多模态建模：Masked-Multimodal-Modeling-MMM" class="headerlink" title="（3）掩码多模态建模：Masked Multimodal Modeling (MMM)"></a>（3）掩码多模态建模：<strong>Masked Multimodal Modeling (MMM)</strong></h4><ul>
<li>同时 mask 图像 patch 和文本 token</li>
<li>Multimodal Encoder 进行联合预测</li>
</ul>
<hr>
<h2 id="4-模块激活策略：Round-Robin"><a href="#4-模块激活策略：Round-Robin" class="headerlink" title="4. 模块激活策略：Round-Robin"></a>4. 模块激活策略：Round-Robin</h2><p>在训练过程中，FLAVA 采用 <strong>Round-Robin Sampling</strong>：</p>
<ul>
<li>每个step只选择一种数据类型：<ul>
<li>image-only → 训练 MIM，激活 image encoder</li>
<li>text-only → 训练 MLM，激活 text encoder</li>
<li>image-text pair → 训练 MMM / ITM / GC，激活所有模块</li>
</ul>
</li>
</ul>
<p>优点：</p>
<ul>
<li>显存节省</li>
<li>稳定优化</li>
<li>三类任务均衡训练</li>
</ul>
<hr>
<h2 id="5-下游任务适配方式"><a href="#5-下游任务适配方式" class="headerlink" title="5. 下游任务适配方式"></a>5. 下游任务适配方式</h2><p>FLAVA 可以灵活用于三类任务：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>下游任务类型</th>
<th>编码器模块</th>
<th>[CLS] 用法</th>
<th>任务头</th>
</tr>
</thead>
<tbody>
<tr>
<td>图像任务</td>
<td>Image Encoder</td>
<td><code>[CLS_I]</code></td>
<td>Linear Head</td>
</tr>
<tr>
<td>文本任务</td>
<td>Text Encoder</td>
<td><code>[CLS_T]</code></td>
<td>Linear Head</td>
</tr>
<tr>
<td>多模态任务</td>
<td>All + Multimodal</td>
<td><code>[CLS_M]</code></td>
<td>分类 / 推理头</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="6-实验结果亮点"><a href="#6-实验结果亮点" class="headerlink" title="6. 实验结果亮点"></a>6. 实验结果亮点</h2><ul>
<li>在 <strong>35 个 benchmark 任务</strong> 上进行评估，涵盖图像、文本、多模态任务</li>
<li><strong>超越CLIP</strong> 在图文融合类任务上的表现（VQA、Hateful Memes等）</li>
<li>即使只用 ImageNet-1k 作为图像数据，也能达到较好视觉结果</li>
<li>文本任务上可媲美 RoBERTa-base</li>
</ul>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/b8bdf6141c6c47e0f947de17bf1d8478.png" alt=""></p>
<hr>
<h2 id="7-我的理解与总结"><a href="#7-我的理解与总结" class="headerlink" title="7. 我的理解与总结"></a>7. 我的理解与总结</h2><blockquote>
<p><strong>FLAVA 是我学习多模态视觉语言模型的重要起点，它统一了对比学习和融合学习两种范式，采用模块化结构，既能灵活适配不同任务，又具备基础模型的可扩展性。</strong></p>
</blockquote>
<p>我特别喜欢它的几点设计：</p>
<ul>
<li>三编码器结构清晰，解耦明确；</li>
<li>Round-Robin 模态调度策略值得借鉴；</li>
<li>模块化训练 + 模块化使用，便于工程部署</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/FLAVA/" rel="tag"># FLAVA</a>
              <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" rel="tag"># 多模态</a>
              <a href="/tags/ViT/" rel="tag"># ViT</a>
              <a href="/tags/VLP/" rel="tag"># VLP</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/07/28/BLIP%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9ABLIP-Bootstrapping-Language-Image-Pre-training-for-Unified-Vision-Language-Understanding-and-Generation/" rel="prev" title="BLIP论文阅读笔记：BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation">
                  <i class="fa fa-angle-left"></i> BLIP论文阅读笔记：BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/07/31/Vision-Language-Pre-training-VLP-%E5%AD%A6%E4%B9%A0%E5%B0%8F%E6%80%BB%E7%BB%93/" rel="next" title="Vision-Language Pre-training (VLP) 学习小总结">
                  Vision-Language Pre-training (VLP) 学习小总结 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2023-12 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">千顷QianQing</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/qianqing26" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"version":"7.1.2","theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.min.js","integrity":"sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
